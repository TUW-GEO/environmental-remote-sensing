{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Forest Classification in Mozambique\n",
    "\n",
    "This notebook demonstrates how to classify forest cover in Mozambique using remote sensing data. The classification is based on data from Sentinel-2 and Landsat. The Data has been prepared and is now available as yearly mosaics split into the different value quantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from enum import Enum\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "import geopandas as gpd\n",
    "import hvplot.pandas\n",
    "import hvplot.xarray  # noqa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from rasterio import Affine\n",
    "from rasterio.features import rasterize\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "Let's start by loading the necessary image data, aswell as the json file that contains the regions of interest (ROIs) for the classification.\n",
    "These ROIs are essentialy polygons covering areas that are either forest or non-forest and are labeled accordingly. This can easily be done with `QGIS`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.perf_counter()\n",
    "# Setup Paths to the data\n",
    "assets: Path = Path(\"assets\").resolve(strict=True)\n",
    "year: int = 2024\n",
    "filepath: Path = next(assets.glob(f\"*{year}*.nc\"))\n",
    "\n",
    "# Load Data\n",
    "ds = xr.open_dataset(filepath)\n",
    "ds = ds.sel(quantile=slice(0.1, 0.9))  # remove outliers\n",
    "slivers: gpd.GeoDataFrame = gpd.read_file(assets / \"label_features_i02.geojson\")\n",
    "\n",
    "# Prepare the crs and affine transformation\n",
    "spatial_ref: dict[str, Any] = ds[\"spatial_ref\"].attrs\n",
    "crs = spatial_ref[\"crs_wkt\"]\n",
    "slivers.to_crs(crs, inplace=True)\n",
    "geotransfrom: list[float] = [float(x) for x in spatial_ref[\"GeoTransform\"].split()]\n",
    "affine = Affine.from_gdal(*geotransfrom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the labels a meaningful name\n",
    "# Although the enum is only used once for the label, it is still a good practice\n",
    "# to use it, as it makes the code more readable and maintainable.\n",
    "\n",
    "\n",
    "class LandCoverType(Enum):\n",
    "    \"\"\"Binding land cover types to their numeric values.\"\"\"\n",
    "\n",
    "    TREE_COVER = 10\n",
    "    SHRUBLAND = 20\n",
    "    GRASSLAND = 30\n",
    "    CROPLAND = 40\n",
    "    SETTLEMENT = 50\n",
    "    BARE_SPARSE = 60\n",
    "    SNOW_ICE_ABSENT = 70\n",
    "    PERMANENT_WATER = 80\n",
    "    INTERMITTENT_WATER = 86\n",
    "    WETLAND = 90"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Next we will plot the image data and the ROIs to get an overview of the data we are working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot RGB Image\n",
    "fig, ax = plt.subplots()\n",
    "ds[[\"Red\", \"Green\", \"Blue\"]].sel(quantile=0.5).to_dataarray().plot.imshow(\n",
    "    robust=True,\n",
    "    ax=ax,\n",
    ")\n",
    "slivers.plot(ax=ax, column=\"label\", cmap=\"RdYlBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Prepare Data for Classification\n",
    "\n",
    "Before we can start the classification, we need to prepare the data, since scikit-learn requires the data to be in a specific format. This involves rasterizing the polygons, creating dataframes from the image data and the polygons, and preparing the features and target variable for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://rasterio.readthedocs.io/en/stable/api/rasterio.features.html#rasterio.features.rasterize\n",
    "# Rasterize the polygons\n",
    "rst = rasterize(\n",
    "    shapes=slivers.to_crs(crs)[[\"geometry\", \"label\"]].to_records(index=False).tolist(),\n",
    "    out_shape=ds[\"Red\"].shape[1:],\n",
    "    transform=affine,\n",
    ")\n",
    "\n",
    "# Create a DataArray from the rasterized polygons\n",
    "label_cube = xr.DataArray(rst, coords={\"y\": ds.y, \"x\": ds.x}, name=\"label\")\n",
    "\n",
    "# Create a DataFrame from the image data\n",
    "feature_frame = (\n",
    "    ds.drop_vars(\"spatial_ref\").to_dataframe().dropna().unstack(level=\"quantile\")\n",
    ")\n",
    "\n",
    "# Rename the columns to include quantile information\n",
    "feature_frame.columns = [\n",
    "    f\"{c[0]}_P{np.round(100 * c[1], 0).astype(int):03}\" for c in feature_frame.columns\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the label data (originally the polygons)\n",
    "label_frame = label_cube.to_dataframe()\n",
    "train_frame = label_frame[label_frame[\"label\"] != 0].join(feature_frame)\n",
    "\n",
    "# Prepare the features and target variable for classification\n",
    "X_features = train_frame.drop(columns=[\"label\"])\n",
    "y_target = train_frame[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Classify Forest Cover with Scikit-learn\n",
    "\n",
    "In the next step, we will use the prepared data to train a Random Forest classifier. The data will first be split into training and testing sets, and then the classifier will be trained on the training set. After training, we can evaluate the classifier's performance on the test set and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_features,\n",
    "    y_target,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Classify Forest Cover with Scikit-learn\n",
    "randforest = RandomForestClassifier(random_state=42)\n",
    "randforest_test = randforest.fit(X_train, y_train)\n",
    "randforest_predict = randforest.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Now that we have trained our model, we can use it to predict the forest cover in the image data. We will use the trained Random Forest model to predict the forest cover for each pixel in the image. As before, we need to prepare the image data, such that it is essentially a vector of pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the image data for classification\n",
    "img = (\n",
    "    ds.drop_vars(\"spatial_ref\")\n",
    "    .to_dataarray()\n",
    "    .transpose(\"x\", \"y\", \"quantile\", \"variable\")\n",
    ")\n",
    "\n",
    "# Reshape the image data\n",
    "num_of_pixels = img.sizes[\"x\"] * img.sizes[\"y\"]\n",
    "num_of_bands = img.sizes[\"quantile\"] * img.sizes[\"variable\"]\n",
    "X_image_data = img.values.reshape(num_of_pixels, num_of_bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using the trained model\n",
    "randforest_predict_img = randforest.predict(X_image_data)\n",
    "randforest_predict_img = randforest_predict_img.reshape(\n",
    "    img.sizes[\"x\"],\n",
    "    img.sizes[\"y\"],\n",
    ").transpose()\n",
    "\n",
    "# Recreate the DataArray for the predicted forest cover\n",
    "predicted_forest = xr.DataArray(\n",
    "    randforest_predict_img,\n",
    "    dims=(\"y\", \"x\"),\n",
    "    coords={\n",
    "        \"x\": ds[\"x\"],\n",
    "        \"y\": ds[\"y\"],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the predicted forest classification\n",
    "predicted_forest.where(predicted_forest == LandCoverType.TREE_COVER.value).hvplot.image(\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    tiles=True,\n",
    "    cmap=\"greens\",\n",
    "    crs=crs,\n",
    "    hover=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = Path(f\"forest_classification_{year}.tif\")\n",
    "predicted_forest.rio.to_raster(savepath, driver=\"GTiff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.perf_counter()\n",
    "total_time = end_time - start_time\n",
    "print(f\"Total execution time: {total_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environmental-remote-sensing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
