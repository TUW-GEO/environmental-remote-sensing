{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import earthaccess as ea\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import rasterio as rio\n",
    "\n",
    "from envrs import hls_tools as hls\n",
    "from envrs import rio_tools as rt\n",
    "from envrs.download_path import make_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# are we authenticated?\n",
    "auth = ea.login()\n",
    "\n",
    "if not auth.authenticated:\n",
    "    # ask for credentials and persist them in a .netrc file\n",
    "    auth.login(strategy=\"interactive\", persist=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Identify the target datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tree = ea.search_datasets(keyword=\"S30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "[d[\"umm\"][\"ShortName\"] for d in dataset_tree]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Query NASA datasets to identify overlapping datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_uri = make_url(\"HLSextent.geojson\")\n",
    "\n",
    "aoi = gpd.read_file(aoi_uri)\n",
    "geometry = aoi.loc[0, \"geometry\"]\n",
    "\n",
    "bbox = geometry.bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "granule_pile = ea.search_data(\n",
    "    short_name=[\"HLSL30\", \"HLSS30\"],\n",
    "    cloud_hosted=True,\n",
    "    temporal=(\"2018-01-01T00:00:00\", \"2024-12-31T23:59:59\"),\n",
    "    bounding_box=bbox,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Examine the contents of a granule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_granule = granule_pile[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_granule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "we can access to all the information about the granule with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(first_granule.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Retain only one of the tiles, when the cloud cover is <90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_valid = 10.0\n",
    "max_cloud = 100 - min_valid\n",
    "target_tile = \"T36KXE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_pile, name_pile = [], []\n",
    "for granule in granule_pile:\n",
    "    # Extract the relevant attributes\n",
    "    granule_attrs = hls.extract_extra_attrs(granule)\n",
    "\n",
    "    # Skip if the target tile does not match\n",
    "    if granule_attrs[\"MGRS_TILE_ID\"] not in target_tile:\n",
    "        continue\n",
    "\n",
    "    # Skip if the cloud cover is too high\n",
    "    if float(granule_attrs[\"CLOUD_COVERAGE\"]) > max_cloud:\n",
    "        continue\n",
    "\n",
    "    # ad the URI's of the selected rasters to the pile\n",
    "    layer_pile.extend(granule.data_links())\n",
    "    name_pile.append(granule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Format the dataframe of the downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_frame = hls.harmonize_hls_frame(hls.tabulate_hls_uris(layer_pile))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Drop the coastal aerosol and the angle bands: they will not be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_frame = sel_frame.drop(columns=[\"CoastalAerosol\", \"SZA\", \"SAA\", \"VZA\", \"VAA\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## Perform download with conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### Set the environment for the download: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/nasa/HLS-Data-Resources/blob/main/python/tutorials/HLS_Tutorial.ipynb\n",
    "env_pairs = {\n",
    "    \"GDAL_HTTP_COOKIEFILE\": \"~/cookies.txt\",\n",
    "    \"GDAL_HTTP_COOKIEJAR\": \"~/cookies.txt\",\n",
    "    \"GDAL_DISABLE_READDIR_ON_OPEN\": \"EMPTY_DIR\",\n",
    "    \"CPL_VSIL_CURL_ALLOWED_EXTENSIONS\": \"TIF\",\n",
    "    \"GDAL_HTTP_UNSAFESSL\": \"YES\",\n",
    "    \"GDAL_HTTP_MAX_RETRY\": \"10\",\n",
    "    \"GDAL_HTTP_RETRY_DELAY\": \"0.5\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR = Path(r\"~/Downloads/hls/automated\").expanduser()\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = [\"Blue\", \"Green\", \"Red\", \"NIRnarrow\", \"SWIR1\", \"SWIR2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rio.Env(**env_pairs) as download_env:\n",
    "    for row_idx, (product_prefix, product_uris) in enumerate(sel_frame.iterrows()):\n",
    "        # Print progress\n",
    "        if row_idx % 100 == 0:\n",
    "            print(f\"{row_idx:>04}\", \"/\", sel_frame.shape[0], product_prefix)\n",
    "\n",
    "        # check if the fmask file exists, skip if that's the case\n",
    "        fmask_path = OUT_DIR / f\"{product_prefix}_fmask.tif\"\n",
    "        if fmask_path.is_file():\n",
    "            continue\n",
    "\n",
    "        # If does not exist, download and save\n",
    "        fmask_pairs, fmask_profiles, fmask_tags = rt.clipped_read(\n",
    "            product_uris[[\"Fmask\"]], aoi\n",
    "        )\n",
    "        rt.write_raster(fmask_pairs, fmask_profiles, fmask_tags, fmask_path)\n",
    "\n",
    "        # Decompose the bit flags\n",
    "        fmask_number = next(iter(fmask_pairs.values()))\n",
    "        fmask_flags = np.flip(\n",
    "            np.unpackbits(np.expand_dims(fmask_number, axis=0), axis=0),\n",
    "            axis=0\n",
    "        )\n",
    "\n",
    "        # Estimate the percentage of clear pixels\n",
    "        # (not cirrus, cloud core/adjacent or shadow casted by them)\n",
    "        is_clear = np.all(fmask_flags[0:4] == 0, axis=0)\n",
    "        perc_valid = 100 * np.sum(is_clear) / fmask_number.size\n",
    "\n",
    "        # Skip band download if the percentage of valid pixels is under threshold\n",
    "        if perc_valid < min_valid:\n",
    "            continue\n",
    "\n",
    "        # check if the band file exists, skip if that's the case\n",
    "        band_path = OUT_DIR / f\"{product_prefix}_bands.tif\"\n",
    "        if band_path.is_file():\n",
    "            continue\n",
    "\n",
    "        # read the bands\n",
    "        band_pairs, band_profiles, band_tags = rt.clipped_read(\n",
    "            product_uris[selected_columns], aoi\n",
    "        )\n",
    "\n",
    "        # Write to the hard drive\n",
    "        rt.write_raster(band_pairs, band_profiles, band_tags, band_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environmental-remote-sensing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
