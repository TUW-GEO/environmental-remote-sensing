{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Access to Historic Soil Moisture Data\n",
    "**Downloading, Reading, and Working with Copernicus WEkEO Soil Water Index 12.5 km** \n",
    "\n",
    "![Source: [Copernicus WEkEO](https://wekeo.copernicus.eu/)](https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fwekeo.copernicus.eu%2F_next%2Fimage%3Furl%3D%252Fpages%252Fhome%252Fwekeo-homepage-bg-desktop.webp%26w%3D3840%26q%3D75&f=1&nofb=1&ipt=742bb5f4855344bc9114d980ee07a1baf8cb3be88d9d5d9ad734b027f4cad372)\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this notebook we will examine how one can obtain historic soil moisture data. We will do this by looking into the [Copernicus WEkEO portal](https://wekeo.copernicus.eu/).\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import hvplot.pandas  # noqa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from dotenv import dotenv_values\n",
    "from hda import Client, Configuration\n",
    "from numpy.lib.recfunctions import unstructured_to_structured\n",
    "from pyswi.swi_ts import calc_swi_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Copernicus WEkEO\n",
    "\n",
    "The name WEkEO (pronounced [wikio]) refer to the four key organisations – EUMETSAT, ECMWF, Copernicus Programme, and Mercator Ocean International, which link to the broader user community (“WE”), with the purpose of knowledge advancement and sharing (“k”), focussing Earth and Environmental Observation (“EO”).\n",
    "\n",
    "The platform is a web-based service that helps people easily access and use Earth observation data. Its main goal is to make it simple for researchers, companies, and decision-makers to get the data they need and analyze it without needing advanced tools or a lot of technical knowledge.\n",
    "\n",
    "## Registration\n",
    "\n",
    "Similarly to H SAF FTP server, we need to register as an user to make full use of WEkEO, although some features are available without an account. We can follow these steps:\n",
    "\n",
    "1. Go to the [homepage of WEkEO](https://wekeo.copernicus.eu/).\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "<a href=\"https://wekeo.copernicus.eu/\"><img width=\"600px\" src=\"../images/home-wekeo-website.png\"></a>\n",
    "</div>\n",
    "\n",
    "2. Click on top right [\"Login\" button](https://identity.prod.wekeo2.eu/authenticationendpoint/login.do?client_id=kNvwaJ1xMQx3zk3Kort05m3D95ca&commonAuthCallerPath=%2Foauth2%2Fauthorize&forceAuth=false&passiveAuth=false&redirect_uri=https%3A%2F%2Fwekeo.copernicus.eu%2Flogin&response_type=code&scope=openid+email+profile+address&sessionDataKey=004043a7-c28f-41d7-bb80-65f072c60185&relyingParty=kNvwaJ1xMQx3zk3Kort05m3D95ca&type=oidc&sp=portallobelia&isSaaSApp=false&authenticators=BasicAuthenticator%3ALOCAL), whereafter we select \"Create an account\" and fill out the form.\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "<a href=\"https://identity.prod.wekeo2.eu/authenticationendpoint/login.do?client_id=kNvwaJ1xMQx3zk3Kort05m3D95ca&commonAuthCallerPath=%2Foauth2%2Fauthorize&forceAuth=false&passiveAuth=false&redirect_uri=https%3A%2F%2Fwekeo.copernicus.eu%2Flogin&response_type=code&scope=openid+email+profile+address&sessionDataKey=004043a7-c28f-41d7-bb80-65f072c60185&relyingParty=kNvwaJ1xMQx3zk3Kort05m3D95ca&type=oidc&sp=portallobelia&isSaaSApp=false&authenticators=BasicAuthenticator%3ALOCAL\"><img width=\"600px\" src=\"../images/login-wekeo-website.png\"></a>\n",
    "</div>\n",
    "\n",
    "3. Now we can login and, for example, look at the available data by clicking on \"Go\" in the \"Data Catalogue\" field in the middle of the screen.\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "<a href=\"https://wekeo.copernicus.eu/my-wekeo\"><img width=\"600px\" src=\"../images/portal-wekeo-website.png\"></a>\n",
    "</div>\n",
    "\n",
    "4. This shows us a data viewer where we can select from many different data products.\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "<a href=\"https://wekeo.copernicus.eu/data?view=catalogue\"><img width=\"600px\" src=\"../images/dataviewer-wekeo-website.png\"></a>\n",
    "</div>\n",
    "\n",
    "We will use the latter step to find the datasets we need and create query strings that we will use in a Python environment. \n",
    "\n",
    "## Harmonized Data Access\n",
    "\n",
    "The Copernicus WEkEO platform offers a straightforward way to access data through its Application Programming Interface (API). APIs enable different programming languages to communicate and exchange information, effectively serving as a bridge for programs to utilize and extend each other's functionalities. In the case of WEkEO, the API is called the Harmonized Data Access (HDA) API, which provides uniform access to the entire WEkEO catalogue, including subsetting and downloading capabilities. We will use the [Python HDA client](https://hda.readthedocs.io/en/latest/index.html) to interact with this API.\n",
    "\n",
    "Install with either pip: \n",
    "\n",
    "```\n",
    "pip install hda\n",
    "```\n",
    "or conda:\n",
    "\n",
    "```\n",
    "conda install -c conda-forge hda\n",
    "```\n",
    "\n",
    "Now, we need to authenticate using the `Configuration` object and provide your account's username and password. As in the previous notebook, we will use a dotenv environment for this purpose. To utilize dotenv, you need to add your username to the `USER_WEKEO` variable and your password to the `PASS_WEKEO` variable in the `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = Configuration(\n",
    "    user=dotenv_values(\".env\")[\"USER_WEKEO\"],\n",
    "    password=dotenv_values(\".env\")[\"PASS_WEKEO\"],\n",
    ")\n",
    "hda_client = Client(config=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Finding Soil Moisture Data\n",
    "\n",
    "To find the SWI 12.5 km dataset in time series format, we have to return to the data viewer in the browser. Click in the \"Layers\" field on the `+` sign, and search for \"Soil Water Index\" in the \"Free Text Search\".\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "<a href=\"https://wekeo.copernicus.eu/data?view=catalogue\"><img width=\"600px\" src=\"../images/swi-search-wekeo-website.png\"></a>\n",
    "</div>\n",
    "\n",
    "Then select the fourth dataset from the top; \"Soil Water Index Time Series 2007-present (discrete global grid), global, daily - version 3\". Click on the download button in the layers field, which unfolds a form which allows subsetting of the data. We can enter here a bounding box (bbox) for Mozambique. Scroll further down and click on \"Show API request(s)\".\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "<a href=\"https://wekeo.copernicus.eu/data?view=catalogue\"><img width=\"600px\" src=\"../images/api-swi-search-wekeo-website.png\"></a>\n",
    "</div>\n",
    "\n",
    "We will copy this query to our Python environment and use the `hda_client` to search for the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    \"dataset_id\": \"EO:CLMS:DAT:CLMS_GLOBAL_SWI_12.5KM_V3_TIME-SERIES_NETCDF\",\n",
    "    \"bbox\": [\n",
    "        30.315,\n",
    "        -27.49,\n",
    "        41.07,\n",
    "        -10.20,\n",
    "    ],\n",
    "    \"itemsPerPage\": 200,\n",
    "    \"startIndex\": 0,\n",
    "}\n",
    "\n",
    "matches = hda_client.search(query)\n",
    "\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "If you are content with the results then you can start the downloading process. Here we again create a directory to contain the downloaded files. The downloaded file with be in NetCDF format. NetCDF is a data formats that is tailored to multi-dimensional array-oriented scientific data with many options to label the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "local_path = \"cgls_swi_12_5\"\n",
    "\n",
    "if not os.path.isdir(local_path):\n",
    "    os.mkdir(local_path)\n",
    "\n",
    "matches.download(download_dir=local_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "The downloaded data is projected on the same Fibonacci grid as the H SAF ASCAT 6.25 km surface soil moisture (see notebook 1). But the NetCDF data format requires another solution to read the data. Hence we will use another package to read the data. We use [`xarray`](https://docs.xarray.dev/en/stable/index.html), which is optimised to work with multi-dimensional arrays. We will introduce this package into more detail later on. We will call the method `to_dataframe()` to turn the `xarray.Dataset` into a `pandas.DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocess(ds: xr.Dataset):\n",
    "    return ds.SWI_010\n",
    "\n",
    "\n",
    "df = xr.open_mfdataset(\n",
    "    \"cgls_swi_12_5/*.nc\",\n",
    "    combine=\"nested\",\n",
    "    parallel=True,\n",
    "    chunks=-1,\n",
    "    preprocess=_preprocess,\n",
    "    compat=\"no_conflicts\",\n",
    "    join=\"outer\",\n",
    ").to_dataframe()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "We use again `hvplot` to validate our search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../src/ssm_cmap.py\n",
    "\n",
    "df.hvplot.points(\n",
    "    x=\"lon\",\n",
    "    y=\"lat\",\n",
    "    c=\"SWI_010\",\n",
    "    groupby=\"time\",\n",
    "    x_sampling=0.16,\n",
    "    y_sampling=0.16,\n",
    "    rasterize=True,\n",
    "    crs=ccrs.PlateCarree(),\n",
    "    tiles=True,\n",
    "    cmap=SSM_CMAP,  # noqa\n",
    "    clim=(0, 100),\n",
    "    frame_width=500,\n",
    "    clabel=\"Soil Water Index\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## What is the Soil Water Index?\n",
    "\n",
    "We have not yet talked about what the data exactly represents. The Soil Water Index is derived from surface soil moisture. The current dataset is derived from H SAF ASCAT 12.5 km and represents modelled approximation of soil water content at deeper layers of the soil. In the above plot we selected moisture content at a 10 cm depth interval. Remember that ASCAT can only probe the surface of soils.\n",
    "\n",
    "The Soil Water Index provides a measure of how wet or dry the soil is over a specific area, ranging between 0 and 1. It is often derived using a combination of satellite data and modeling techniques. One commonly used approach to derive the SWI is through the TU Wien model[^1]\n",
    "\n",
    "The equation to derive the SWI typically involves a convolution of surface soil moisture observations with an exponential filter. This process helps in estimating the root-zone soil moisture, which is more relevant for agricultural and hydrological applications. The general form of the equation can be described as follows:\n",
    "\n",
    "$$ \\text{SWI} = \\frac{\\sum_{i=0}^{n} w_i \\cdot SSM_i}{\\sum_{i=0}^{n} w_i} $$\n",
    "\n",
    "Where:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{SWI} &\\quad \\text{: Soil Water Index} \\\\\n",
    "\\text{SSM}_i &\\quad \\text{: surface soil moisture at time step} i \\\\\n",
    "w_i &\\quad \\text{: the weight assigned to the surface soil moisture at time step} i \\\\\n",
    "n &\\quad \\text{: number of time steps considered in the convolution}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The weights $w_i$ are often determined using an exponential decay function, which gives more importance to recent observations. The exponential decay function can be expressed as:\n",
    "\n",
    "$$ w_i = e^{-\\frac{t_i}{T}} $$\n",
    "\n",
    "Where:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "t_i &\\quad \\text{: the time difference between the current time step and the time step} i \\\\\n",
    "T  &\\quad \\text{: a characteristic time scale that determines the rate of decay of the weights}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "This approach allows the SWI to reflect the cumulative effect of surface soil moisture over a period, providing a more stable and representative measure of the soil moisture conditions in the root zone.\n",
    "\n",
    "One will observe that the SWI at depth is often less variable (more stable) than contemporaneous surface soil moisture with only delayed and dampened responses to external forcing (e.g. precipitation). We can visualize this by applying the SWI algorithm to one of the five timeseries introduced in notebook 1.\n",
    "\n",
    "Let's select only the year 2024 from the H SAF ASCAT 6.25 km surface soil moisture for Buzi:\n",
    "\n",
    "[^1]: W. Wagner, Lemoine, G., Rott, H., 1999, A Method for Estimating Soil Moisture from ERS Scatterometer and Soil Data, Remote Sensing of Environment, Volume 70-2, pp. 191-207, doi: [S0034-4257(99)00036-X](https://doi.org/10.1016/S0034-4257(99)00036-X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../src/download_path.py\n",
    "\n",
    "sm_ts = (\n",
    "    pd.read_csv(\n",
    "        make_url(\"ascat-6_25_ssm_timeseries.csv\"),  # noqa\n",
    "        index_col=\"time\",\n",
    "        parse_dates=True,  # noqa\n",
    "    )\n",
    "    .loc[\"2024\"]\n",
    "    .dropna()\n",
    ")\n",
    "\n",
    "sm_ts = sm_ts[sm_ts.name == \"Buzi\"].sort_index()\n",
    "sm_ts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "Now we can use the TU Wien developed package `pyswi` to calculate time series SWI. First we have to prepare the `numpy` arrays for the SSM and Julian time stamps[^2], like so:\n",
    "\n",
    "[^2]: Julian time stamps, also known as Julian dates, are continuous counts of days and fractions of days since a specific starting point, commonly used in astronomy and scientific applications to measure time intervals precisely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "swi_jd = sm_ts.index.to_julian_date().values.astype(np.float64)\n",
    "sm = sm_ts[\"surface_soil_moisture\"].values\n",
    "\n",
    "dtype = np.dtype([(\"sm_jd\", np.float64), (\"sm\", np.float32)])\n",
    "ssm_ts = unstructured_to_structured(\n",
    "    np.hstack((swi_jd[:, np.newaxis], sm[:, np.newaxis])), dtype=dtype\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "Now we can calculate the SWI. Here we calculate it for depth intervals of 5, 50, and 100 cm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_value = np.array([5, 50, 100], dtype=np.int32)\n",
    "swi_ts, gain_out = calc_swi_ts(ssm_ts, swi_jd, t_value=t_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "After which, we convert the `numpy` arrays back to a pandas `DataFrame` and merge it with the original SSM data. This requires the Julian time steps to be converted back to a normal pandas `datetime` type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "swi_ts = pd.DataFrame(swi_ts)\n",
    "swi_ts[\"time\"] = pd.to_datetime(swi_ts[\"swi_jd\"] - 2440587.5, unit=\"D\")\n",
    "ts = pd.merge_asof(sm_ts, swi_ts.set_index(\"time\"), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "Finally, we plot the results where see the lagged and dampened response of soil moisture content with increasing depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.hvplot.line(\n",
    "    y=[\"surface_soil_moisture\", \"swi_5\", \"swi_50\", \"swi_100\"], frame_width=800\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environmental-remote-sensing",
   "language": "python",
   "name": "environmental-remote-sensing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
