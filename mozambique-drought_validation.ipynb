{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Validation of Remotely Sensed Droughts\n",
    "**Comparing Spatial Trends**\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this notebook we continue with drought indicators, as introduced in notebook1. The h SAF ASCAT drought indicator is based on soil moisture (temporal) anomalies, which require a long-term mean for a robust measure. The anomalies are than calculated as standardized deviations from the long-term mean.\n",
    "\n",
    "\n",
    "AS explained in the first notebook, ASCAT SSM comes in units degree of saturation. Although spatial patterns,... , relative changes as used for drought anomaly detection\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import datashader as ds\n",
    "import holoviews as hv\n",
    "import hvplot.pandas  # noqa\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Standardized Precipitation-Evapotranspiration Index\n",
    "\n",
    "SPEI (Standardized Precipitation-Evapotranspiration Index) \n",
    "\n",
    "Definition: \n",
    "\n",
    "    SPEI is a more comprehensive index that takes into account both precipitation and potential evapotranspiration (PET), which is a measure of the atmospheric demand for water.\n",
    "     \n",
    "\n",
    "Calculation: \n",
    "\n",
    "    SPEI is derived from the difference between precipitation and PET, accounting for both water supply (precipitation) and demand (evapotranspiration).\n",
    "    SPEI values are standardized to facilitate comparison across different regions and timescales.\n",
    "     \n",
    "\n",
    "Drought Classification: \n",
    "\n",
    "    Similar to SPI, SPEI values range from strongly negative (indicating dry conditions) to strongly positive (indicating wet conditions).\n",
    "    Drought categories are typically defined similarly to SPI:\n",
    "        Extremely Dry: SPEI ≤ -2.0\n",
    "        Severely Dry: -2.0 < SPEI ≤ -1.5\n",
    "        Moderately Dry: -1.5 < SPEI ≤ -1.0\n",
    "        Near Normal: -1.0 < SPEI ≤ 1.0\n",
    "        Moderately Wet: 1.0 < SPEI ≤ 1.5\n",
    "        Very Wet: 1.5 < SPEI ≤ 2.0\n",
    "        Extremely Wet: SPEI > 2.0\n",
    "         \n",
    "     \n",
    "\n",
    "Comparison \n",
    "\n",
    "Strengths of SPI: \n",
    "\n",
    "    Simplicity: SPI is easier to calculate because it only requires precipitation data.\n",
    "    Wide Acceptance: SPI is one of the most widely used and accepted drought indices globally.\n",
    "     \n",
    "\n",
    "Strengths of SPEI: \n",
    "\n",
    "    Comprehensiveness: SPEI incorporates both precipitation and evapotranspiration, providing a more complete picture of water availability.\n",
    "    Climate Change: SPEI is better suited for capturing the effects of rising temperatures on drought conditions, as increasing temperatures lead to higher evapotranspiration and thus exacerbate drought conditions even if precipitation remains constant.\n",
    "     \n",
    "\n",
    "Differences in Drought Classification: \n",
    "\n",
    "    Sensitivity to Temperature: Because SPEI includes PET, it is more sensitive to changes in temperature. In regions experiencing warming trends, SPEI may indicate more severe or frequent droughts compared to SPI.\n",
    "    Seasonal Variations: SPEI may show stronger seasonal variations due to differences in evapotranspiration rates across seasons.\n",
    "    Region-Specific Differences: In regions with significant temperature variations (e.g., arid regions), SPEI may provide a more accurate assessment of drought conditions compared to SPI.\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./src/download_path.py\n",
    "\n",
    "url = make_url(\"spei-6_25_monthly.csv\")  # noqa\n",
    "df1 = pd.read_csv(\n",
    "    url,\n",
    "    index_col=[\"time\", \"location_id\"],\n",
    "    parse_dates=[\"time\"],\n",
    ")\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "Now let's also load our own data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = make_url(\"ascat-6_25_ssm_monthly.csv\")  # noqa\n",
    "df2 = pd.read_csv(\n",
    "    url,\n",
    "    index_col=[\"time\", \"location_id\"],\n",
    "    parse_dates=[\"time\"],\n",
    ")[[\"zscore\"]]\n",
    "df2 = df2[df2.index <= df1.index.max()]\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## \n",
    "\n",
    "merge() performs join operations similar to relational databases like SQL. Users who are familiar with SQL but new to pandas can reference a \n",
    "\n",
    "We use here the default operation which is \"left join\". THis is a type of join used to combine rows from two tables based on a related column between them. It returns all rows from the left table and includes matched rows from the right table. If there is no match, the result is `np.nan` for columns from the right table. Since we assigned indexes, where time and location_id define a unique observation, the join operations is based on this `pandas.MultIndex`. In other words, the left join ensures that all rows from the left table are included in the result set, even if there are no corresponding rows in the right table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide = df1.join(df2)\n",
    "df_wide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Simplifying Drought Severity with Data Binning\n",
    "\n",
    "We will now turn the numeric data of the drought indicators; `\"spei\"` and `\"zscore\"` to discrete categories by using pandas `cut` method. In pandas, binning data (also known as discretization or quantization) is a technique where continuous numerical data is divided into discrete bins or intervals. This process can be useful for various purposes such as simplifying data, handling outliers, creating histograms, and preparing data for machine learning algorithms that require categorical input. We also provide labels for the binned data turning the columns into pandas categorical data types. Pandas categorical data types are designed to represent data that takes on a limited and usually fixed number of possible values (categories). This type is often used for categorical variables, such as gender, days of the week, or survey responses. They provide efficient storage and operations for categorical data, with the ability to handle category ordering and missing values.\n",
    "\n",
    "The act of binning and labelling anomaly data according to drought intensity is relative subjective exercise, where the threshold of the bins are subject of discussion and arbitrarily assigned. We follow here the recommendations by World Meteorological Organization and the definitions of McKee et al. 1993^1 for standardized SM based drought indices, where a \"moderate\" drought starts at 1 unit of standard deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "drought_labels = np.array([\"Extreme\", \"Severe\", \"moderate\", \"mild\", \"normal\"])\n",
    "zscore_thresholds = [df_wide[\"zscore\"].min(), -2, -1.5, -1, 0, df_wide[\"zscore\"].max()]\n",
    "spei_thresholds = [df_wide[\"spei\"].min(), -2, -1.5, -1, 0, df_wide[\"spei\"].max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Now we can use the labels and thresholds to bind the columns of thew drouhgt indicators. We make a copy of the original data to preserve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide_cat = df_wide.copy()\n",
    "df_wide_cat[\"zscore\"] = pd.cut(df_wide.zscore, zscore_thresholds, labels=drought_labels)\n",
    "df_wide_cat[\"spei\"] = pd.cut(df_wide.spei, spei_thresholds, labels=drought_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "The simplified labelled drought indicators will now enables us a first step to assessing the spatial/areal extent.\n",
    "\n",
    "To check on our results we will recreate our plot from notebook 1 but now with categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long = df_wide_cat.melt(id_vars=[\"latitude\", \"longitude\"], ignore_index=False)\n",
    "df_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long.hvplot.points(\n",
    "    x=\"longitude\",\n",
    "    y=\"latitude\",\n",
    "    groupby=[\"variable\", \"time\"],\n",
    "    x_sampling=0.1,\n",
    "    y_sampling=0.1,\n",
    "    rasterize=True,\n",
    "    aggregator=ds.count_cat(\"value\"),\n",
    "    datashade=True,\n",
    "    crs=ccrs.PlateCarree(),\n",
    "    tiles=True,\n",
    "    frame_width=500,\n",
    "    clabel=\"Drought anomaly\",\n",
    "    cmap={\n",
    "        \"Extreme\": \"#bb0c0c\",\n",
    "        \"Severe\": \"#c57b19\",\n",
    "        \"moderate\": \"#b1bb29\",\n",
    "        \"mild\": \"#1cd87a\",\n",
    "        \"normal\": \"#ffffff\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Spatial Extent\n",
    "\n",
    "Letls npow turn to calculating the spatial trend. For this we can conviently use the pandas value_count on the two categorical columns of spei and ssm zscore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_spei = df_wide_cat.groupby(level=0)[\"spei\"].value_counts(normalize=True).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_zscore = (\n",
    "    df_wide_cat.groupby(level=0)[\"zscore\"].value_counts(normalize=True).unstack()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "We combine these results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_keys = pd.Index([\"spei\", \"zscore\"], name=\"indicator\")\n",
    "df_drought_extend = pd.concat(\n",
    "    [col_spei, col_zscore],\n",
    "    keys=new_keys,\n",
    ")\n",
    "df_drought_extend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "mozambique_droughts = [\n",
    "    {\"time\": \"2007-01-01\", \"people_affected\": 0.52},\n",
    "    {\"time\": \"2008-01-01\", \"people_affected\": 0.5},\n",
    "    {\"time\": \"2010-01-01\", \"people_affected\": 0.46},\n",
    "    {\"time\": \"2016-01-01\", \"people_affected\": 2.30},\n",
    "    {\"time\": \"2020-01-01\", \"people_affected\": 2.7},\n",
    "    {\"time\": \"2021-01-01\", \"people_affected\": 1.56},\n",
    "]\n",
    "\n",
    "df_droughts = pd.DataFrame(mozambique_droughts).assign(y=1)\n",
    "df_droughts[\"time\"] = pd.to_datetime(df_droughts[\"time\"], format=\"%Y-%M-%d\")\n",
    "df_droughts.set_index(\"time\", inplace=True)\n",
    "labels = df_droughts.hvplot.labels(\n",
    "    x=\"time\",\n",
    "    y=\"y\",\n",
    "    text=\"{people_affected} mill. people\",\n",
    "    text_baseline=\"bottom_left\",\n",
    "    hover=False,\n",
    "    angle=85,\n",
    "    text_font_size=\"14px\",\n",
    ")\n",
    "offset = hv.dim(\"y\") - 0.1\n",
    "points = df_droughts.hvplot.points(\n",
    "    x=\"time\", y=\"y\", color=\"black\", hover=False, transforms={\"y\": offset}\n",
    ")\n",
    "df_drought_extend.hvplot.area(\n",
    "    x=\"time\",\n",
    "    y=drought_labels[::-1][2:],\n",
    "    groupby=\"indicator\",\n",
    "    hover=False,\n",
    "    frame_width=800,\n",
    "    padding=((0.1, 0.1), (0, 0.9)),\n",
    ") * labels * points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = make_url(\"drought_indices-6_25_monthly.csv\")  # noqa\n",
    "df_drought_indices = pd.read_csv(\n",
    "    url,\n",
    "    index_col=[\"time\", \"location_id\"],\n",
    "    parse_dates=[\"time\"],\n",
    ")\n",
    "df_drought_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_drought_areal_extend(df):\n",
    "    # make drought categories\n",
    "    col_names = df.drop(columns=[\"longitude\", \"latitude\"]).columns\n",
    "    for name in col_names:\n",
    "        min_border = df[name].min()\n",
    "        max_border = df[name].max()\n",
    "        thresholds = np.array(\n",
    "            [\n",
    "                min_border if min_border < -2 else -2.1,\n",
    "                -2,\n",
    "                -1.5,\n",
    "                -1,\n",
    "                0,\n",
    "                max_border if max_border > 0 else 0.1,\n",
    "            ]\n",
    "        )\n",
    "        df[name] = pd.cut(df[name], thresholds, labels=drought_labels)\n",
    "\n",
    "    # calculate relative extend of drought\n",
    "    new_df = pd.concat(\n",
    "        [\n",
    "            df.groupby(level=0)[col].value_counts(normalize=True).unstack()\n",
    "            for col in col_names\n",
    "        ],\n",
    "        keys=pd.Index(col_names, name=\"indicator\"),\n",
    "    )\n",
    "    return new_df\n",
    "\n",
    "\n",
    "df_drought_extend = calc_drought_areal_extend(df_drought_indices.copy())\n",
    "df_drought_extend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drought_extend.hvplot.area(\n",
    "    x=\"time\",\n",
    "    y=drought_labels[::-1][2:],\n",
    "    groupby=\"indicator\",\n",
    "    hover=False,\n",
    "    frame_width=800,\n",
    "    padding=((0.1, 0.1), (0, 0.9)),\n",
    ") * labels * points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long.hvplot.points(\n",
    "    x=\"longitude\",\n",
    "    y=\"latitude\",\n",
    "    groupby=[\"variable\", \"time\"],\n",
    "    x_sampling=0.1,\n",
    "    y_sampling=0.1,\n",
    "    rasterize=True,\n",
    "    aggregator=ds.count_cat(\"value\"),\n",
    "    datashade=True,\n",
    "    crs=ccrs.PlateCarree(),\n",
    "    tiles=True,\n",
    "    frame_width=500,\n",
    "    clabel=\"Drought anomaly\",\n",
    "    cmap={\n",
    "        \"Extreme\": \"#bb0c0c\",\n",
    "        \"Severe\": \"#c57b19\",\n",
    "        \"moderate\": \"#b1bb29\",\n",
    "        \"mild\": \"#1cd87a\",\n",
    "        \"normal\": \"#ffffff\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_confusion = pd.crosstab(df_wide_cat[\"spei\"], df_wide_cat[\"zscore\"], dropna=False)\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_drought = df_confusion.loc[\"drought\", :].sum()\n",
    "sensitivity = df_confusion.loc[\"drought\", \"drought\"] / tot_drought\n",
    "sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_no_drought = df_confusion.loc[\"no-drought\", :].sum()\n",
    "specificity = df_confusion.loc[\"no-drought\", \"no-drought\"] / tot_no_drought\n",
    "specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_accuracy = (sensitivity + specificity) / 2\n",
    "balanced_accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environmental-remote-sensing",
   "language": "python",
   "name": "environmental-remote-sensing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
